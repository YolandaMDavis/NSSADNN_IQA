{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wildtrack_multitask_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "145BSapb-tD6YRaQ-kkbOu1ho99LkXdD9",
      "authorship_tag": "ABX9TyOgYalqHVpe2xFdBkD+Sk3Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YolandaMDavis/NSSADNN_IQA/blob/wildtrack-iqa/wildtrack_multitask_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86zTQbaATADZ",
        "outputId": "2ca15a74-a798-4952-d255-a822d5202398"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#Only needed to copy data to local drive can be skipped if zip file is already available in working folder\n",
        "import shutil\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive') # for google colab. adjust accordingly\n",
        "PARENT_DIR = '/content/drive/MyDrive/Wildtrack Group/IQA' \n",
        "\n",
        "# copy and extract tar file\n",
        "shutil.copy(PARENT_DIR + '/data/WildTrack_Raw.zip', 'WildTrack_Raw.zip')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone repo and copy in images. change working directory to repo's wildtrack branch\n",
        "\n",
        "!git clone https://github.com/YolandaMDavis/NSSADNN_IQA.git\n",
        "!mv WildTrack_Raw.zip NSSADNN_IQA/.\n",
        "%cd \"NSSADNN_IQA\"\n",
        "!git checkout wildtrack-iqa\n",
        "\n",
        "with ZipFile('WildTrack_Raw.zip', 'r') as zipObj:\n",
        "   # Extract all the contents of zip file in current directory\n",
        "   zipObj.extractall()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdsaQ5gLscbH",
        "outputId": "5112ff50-7052-4c31-9246-e3148d76f8c6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NSSADNN_IQA'...\n",
            "remote: Enumerating objects: 58, done.\u001b[K\n",
            "remote: Counting objects: 100% (58/58), done.\u001b[K\n",
            "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
            "remote: Total 58 (delta 27), reused 29 (delta 8), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (58/58), done.\n",
            "/content/NSSADNN_IQA\n",
            "Branch 'wildtrack-iqa' set up to track remote branch 'wildtrack-iqa' from 'origin'.\n",
            "Switched to a new branch 'wildtrack-iqa'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# director variables\n",
        "root_dir = '/content/NSSADNN_IQA'\n",
        "data_dir = root_dir + '/RAW'\n",
        "image_reference_file_suffix = '_image_references.csv'"
      ],
      "metadata": {
        "id": "ekH386NcXSpL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import yaml\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "def generate_data_files(sample_percentage=1):\n",
        "\n",
        "    image_reference_list = []\n",
        "\n",
        "    subdirectories = list(os.walk(data_dir, topdown=False))[:-1]\n",
        "    for subdir in subdirectories:\n",
        "        image_location = subdir[0]\n",
        "        images = subdir[2]\n",
        "        species_rating = image_location.rsplit('/', 1)[-1].replace('_', ' ')\n",
        "        score = int(species_rating.rsplit(' ', 1)[-1])\n",
        "        species_class = species_rating.rsplit(' ', 1)[:-1][0]\n",
        "        if len(species_class.rsplit(' ', 1)) > 1:\n",
        "            species = species_class.rsplit(' ')[0]\n",
        "            animal_class = ' '.join(species_class.rsplit(' ')[1:])\n",
        "        else:\n",
        "            animal_class = 'Unknown'\n",
        "            species = species_class\n",
        "\n",
        "        for image in images:\n",
        "            image_reference = (image_location, species, animal_class, image, score)\n",
        "            image_reference_list.append(image_reference)\n",
        "\n",
        "    # shuffle then split\n",
        "    seed = 1234\n",
        "    random.Random(seed).shuffle(image_reference_list)\n",
        "    training = image_reference_list[:int(len(image_reference_list) * 0.6 * sample_percentage)]\n",
        "    validation = image_reference_list[-int(len(image_reference_list) * 0.2 * sample_percentage):]\n",
        "    testing = image_reference_list[-int(len(image_reference_list) * 0.2 * sample_percentage):]\n",
        "\n",
        "    # generated reference splits\n",
        "    for dataset in [('training', training), ('validation', validation), ('testing', testing)]:\n",
        "        ref_file_name = root_dir + '/' + dataset[0] + image_reference_file_suffix\n",
        "        with open(ref_file_name, 'w', newline='') as csvfile:\n",
        "            image_ref_writer = csv.writer(csvfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_NONNUMERIC)\n",
        "            image_ref_writer.writerows(dataset[1])\n"
      ],
      "metadata": {
        "id": "WTrUK_gJY7Ze"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# take a percentage of the full data set as a training/test/validation sample\n",
        "sample_size=.1\n",
        "generate_data_files(sample_size)"
      ],
      "metadata": {
        "id": "kBYqLFkEeXJ5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "import torch.nn as nn\n",
        "import random\n",
        "from network import NSSADNN\n",
        "from WildTrackDataset import WildTrackDataset"
      ],
      "metadata": {
        "id": "xs7-7IR8dYVZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_model = root_dir + \"/model.pth\"\n",
        "\n",
        "seed = random.randint(10000000, 99999999)\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "print(\"seed:\", seed)\n",
        "\n",
        "config = {}\n",
        "config[\"patch_size\"] = 32\n",
        "config[\"stride\"] = 16\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "train_dataset = WildTrackDataset(root_dir + '/' + 'training' + image_reference_file_suffix, config, \"train\")\n",
        "val_dataset = WildTrackDataset(root_dir + '/' + 'validation' + image_reference_file_suffix, config, \"validation\")\n",
        "test_dataset = WildTrackDataset(root_dir + '/' + 'testing' + image_reference_file_suffix, config, \"testing\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vt81g7b6ZYlN",
        "outputId": "cc96dba8-54a7-4218-cbcc-e1e244cd69ce"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "seed: 97693607\n",
            "Processing file number:0\n",
            "Processing file number:1\n",
            "Processing file number:2\n",
            "Processing file number:3\n",
            "Processing file number:4\n",
            "Processing file number:5\n",
            "Processing file number:6\n",
            "Processing file number:7\n",
            "Processing file number:8\n",
            "Processing file number:9\n",
            "Processing file number:10\n",
            "Processing file number:11\n",
            "Processing file number:12\n",
            "Processing file number:13\n",
            "Processing file number:14\n",
            "Processing file number:15\n",
            "Processing file number:16\n",
            "Processing file number:17\n",
            "Processing file number:18\n",
            "Processing file number:19\n",
            "Processing file number:20\n",
            "Processing file number:21\n",
            "Processing file number:22\n",
            "Processing file number:23\n",
            "Processing file number:24\n",
            "Processing file number:25\n",
            "Processing file number:26\n",
            "Processing file number:27\n",
            "Processing file number:28\n",
            "Processing file number:29\n",
            "Processing file number:30\n",
            "Processing file number:31\n",
            "Processing file number:32\n",
            "Processing file number:33\n",
            "Processing file number:34\n",
            "Processing file number:35\n",
            "Processing file number:36\n",
            "Processing file number:37\n",
            "Processing file number:38\n",
            "Processing file number:39\n",
            "Processing file number:40\n",
            "Processing file number:41\n",
            "Processing file number:42\n",
            "Processing file number:43\n",
            "Processing file number:44\n",
            "Processing file number:45\n",
            "Processing file number:46\n",
            "Processing file number:47\n",
            "Processing file number:48\n",
            "Processing file number:49\n",
            "Processing file number:50\n",
            "Processing file number:51\n",
            "Processing file number:52\n",
            "Processing file number:53\n",
            "Processing file number:54\n",
            "Processing file number:55\n",
            "Processing file number:56\n",
            "Processing file number:57\n",
            "Processing file number:58\n",
            "Processing file number:59\n",
            "Processing file number:60\n",
            "Processing file number:61\n",
            "Processing file number:62\n",
            "Processing file number:63\n",
            "Processing file number:64\n",
            "Processing file number:65\n",
            "Processing file number:66\n",
            "Processing file number:67\n",
            "Processing file number:68\n",
            "Processing file number:69\n",
            "Processing file number:70\n",
            "Processing file number:71\n",
            "Processing file number:72\n",
            "Processing file number:73\n",
            "Processing file number:74\n",
            "Processing file number:75\n",
            "Processing file number:76\n",
            "Processing file number:77\n",
            "Processing file number:78\n",
            "Processing file number:79\n",
            "Processing file number:80\n",
            "Processing file number:81\n",
            "Processing file number:82\n",
            "Processing file number:83\n",
            "Processing file number:84\n",
            "Processing file number:85\n",
            "Processing file number:86\n",
            "Processing file number:87\n",
            "Processing file number:88\n",
            "Processing file number:89\n",
            "Processing file number:90\n",
            "Processing file number:91\n",
            "Processing file number:92\n",
            "Processing file number:93\n",
            "Processing file number:94\n",
            "Processing file number:95\n",
            "Processing file number:96\n",
            "Processing file number:97\n",
            "Processing file number:98\n",
            "Processing file number:99\n",
            "Processing file number:100\n",
            "Processing file number:101\n",
            "Processing file number:102\n",
            "Processing file number:103\n",
            "Processing file number:104\n",
            "Processing file number:105\n",
            "Processing file number:106\n",
            "Processing file number:107\n",
            "Processing file number:108\n",
            "Processing file number:109\n",
            "Processing file number:110\n",
            "Processing file number:111\n",
            "Processing file number:112\n",
            "Processing file number:113\n",
            "Processing file number:114\n",
            "Processing file number:115\n",
            "Processing file number:116\n",
            "Processing file number:117\n",
            "Processing file number:118\n",
            "Processing file number:119\n",
            "Processing file number:120\n",
            "Processing file number:121\n",
            "Processing file number:122\n",
            "Processing file number:123\n",
            "Processing file number:124\n",
            "Processing file number:125\n",
            "Processing file number:126\n",
            "Processing file number:127\n",
            "Processing file number:128\n",
            "Processing file number:129\n",
            "Processing file number:130\n",
            "Processing file number:131\n",
            "Processing file number:132\n",
            "Processing file number:133\n",
            "Processing file number:134\n",
            "Processing file number:135\n",
            "Processing file number:136\n",
            "Processing file number:137\n",
            "Processing file number:138\n",
            "Processing file number:139\n",
            "Processing file number:140\n",
            "Processing file number:141\n",
            "Processing file number:142\n",
            "Processing file number:143\n",
            "Processing file number:144\n",
            "Processing file number:145\n",
            "Processing file number:146\n",
            "Processing file number:147\n",
            "Processing file number:148\n",
            "Processing file number:149\n",
            "Processing file number:150\n",
            "Processing file number:151\n",
            "Processing file number:152\n",
            "Processing file number:153\n",
            "Processing file number:154\n",
            "Processing file number:155\n",
            "Processing file number:156\n",
            "Processing file number:157\n",
            "Processing file number:158\n",
            "Processing file number:159\n",
            "Processing file number:160\n",
            "Processing file number:161\n",
            "Processing file number:162\n",
            "Processing file number:163\n",
            "Processing file number:164\n",
            "Processing file number:165\n",
            "Processing file number:166\n",
            "Processing file number:167\n",
            "Processing file number:168\n",
            "Processing file number:169\n",
            "Processing file number:170\n",
            "Processing file number:171\n",
            "Processing file number:172\n",
            "Processing file number:173\n",
            "Processing file number:174\n",
            "Processing file number:175\n",
            "Processing file number:176\n",
            "Processing file number:177\n",
            "Processing file number:178\n",
            "Processing file number:179\n",
            "Processing file number:180\n",
            "Processing file number:181\n",
            "Processing file number:182\n",
            "Processing file number:183\n",
            "Processing file number:184\n",
            "Processing file number:185\n",
            "Processing file number:186\n",
            "Processing file number:187\n",
            "Processing file number:188\n",
            "Processing file number:189\n",
            "Processing file number:190\n",
            "Processing file number:191\n",
            "Processing file number:192\n",
            "Processing file number:193\n",
            "Processing file number:194\n",
            "Processing file number:195\n",
            "Processing file number:196\n",
            "Processing file number:197\n",
            "Processing file number:198\n",
            "Processing file number:199\n",
            "Processing file number:200\n",
            "Processing file number:201\n",
            "Processing file number:202\n",
            "Processing file number:203\n",
            "Processing file number:204\n",
            "Processing file number:205\n",
            "Processing file number:206\n",
            "Processing file number:207\n",
            "Processing file number:208\n",
            "Processing file number:209\n",
            "Processing file number:210\n",
            "Processing file number:211\n",
            "Processing file number:212\n",
            "Processing file number:213\n",
            "Processing file number:214\n",
            "Processing file number:215\n",
            "Processing file number:216\n",
            "Processing file number:217\n",
            "Processing file number:218\n",
            "Processing file number:219\n",
            "Processing file number:220\n",
            "Processing file number:221\n",
            "Processing file number:222\n",
            "Processing file number:223\n",
            "Processing file number:224\n",
            "Processing file number:225\n",
            "Processing file number:226\n",
            "Processing file number:227\n",
            "Processing file number:228\n",
            "Processing file number:229\n",
            "Processing file number:230\n",
            "Processing file number:231\n",
            "Processing file number:232\n",
            "Processing file number:233\n",
            "Processing file number:234\n",
            "Processing file number:235\n",
            "Processing file number:236\n",
            "Processing file number:237\n",
            "Processing file number:238\n",
            "Processing file number:239\n",
            "Processing file number:240\n",
            "Processing file number:241\n",
            "Processing file number:242\n",
            "Processing file number:243\n",
            "Processing file number:244\n",
            "Processing file number:245\n",
            "Processing file number:246\n",
            "Processing file number:247\n",
            "Processing file number:248\n",
            "Processing file number:249\n",
            "Processing file number:250\n",
            "Processing file number:251\n",
            "Processing file number:252\n",
            "Processing file number:253\n",
            "Processing file number:254\n",
            "Processing file number:255\n",
            "Processing file number:256\n",
            "Processing file number:257\n",
            "Processing file number:258\n",
            "Processing file number:259\n",
            "Processing file number:260\n",
            "Processing file number:261\n",
            "Processing file number:262\n",
            "Processing file number:263\n",
            "Processing file number:264\n",
            "Processing file number:265\n",
            "Processing file number:266\n",
            "Processing file number:267\n",
            "Processing file number:268\n",
            "Processing file number:269\n",
            "Processing file number:270\n",
            "Processing file number:271\n",
            "Processing file number:272\n",
            "Processing file number:273\n",
            "Processing file number:274\n",
            "Processing file number:275\n",
            "Processing file number:276\n",
            "Processing file number:277\n",
            "Processing file number:278\n",
            "Processing file number:279\n",
            "Processing file number:280\n",
            "Processing file number:281\n",
            "Processing file number:282\n",
            "Processing file number:283\n",
            "Processing file number:284\n",
            "Processing file number:285\n",
            "Processing file number:286\n",
            "Processing file number:287\n",
            "Processing file number:288\n",
            "Processing file number:0\n",
            "Processing file number:1\n",
            "Processing file number:2\n",
            "Processing file number:3\n",
            "Processing file number:4\n",
            "Processing file number:5\n",
            "Processing file number:6\n",
            "Processing file number:7\n",
            "Processing file number:8\n",
            "Processing file number:9\n",
            "Processing file number:10\n",
            "Processing file number:11\n",
            "Processing file number:12\n",
            "Processing file number:13\n",
            "Processing file number:14\n",
            "Processing file number:15\n",
            "Processing file number:16\n",
            "Processing file number:17\n",
            "Processing file number:18\n",
            "Processing file number:19\n",
            "Processing file number:20\n",
            "Processing file number:21\n",
            "Processing file number:22\n",
            "Processing file number:23\n",
            "Processing file number:24\n",
            "Processing file number:25\n",
            "Processing file number:26\n",
            "Processing file number:27\n",
            "Processing file number:28\n",
            "Processing file number:29\n",
            "Processing file number:30\n",
            "Processing file number:31\n",
            "Processing file number:32\n",
            "Processing file number:33\n",
            "Processing file number:34\n",
            "Processing file number:35\n",
            "Processing file number:36\n",
            "Processing file number:37\n",
            "Processing file number:38\n",
            "Processing file number:39\n",
            "Processing file number:40\n",
            "Processing file number:41\n",
            "Processing file number:42\n",
            "Processing file number:43\n",
            "Processing file number:44\n",
            "Processing file number:45\n",
            "Processing file number:46\n",
            "Processing file number:47\n",
            "Processing file number:48\n",
            "Processing file number:49\n",
            "Processing file number:50\n",
            "Processing file number:51\n",
            "Processing file number:52\n",
            "Processing file number:53\n",
            "Processing file number:54\n",
            "Processing file number:55\n",
            "Processing file number:56\n",
            "Processing file number:57\n",
            "Processing file number:58\n",
            "Processing file number:59\n",
            "Processing file number:60\n",
            "Processing file number:61\n",
            "Processing file number:62\n",
            "Processing file number:63\n",
            "Processing file number:64\n",
            "Processing file number:65\n",
            "Processing file number:66\n",
            "Processing file number:67\n",
            "Processing file number:68\n",
            "Processing file number:69\n",
            "Processing file number:70\n",
            "Processing file number:71\n",
            "Processing file number:72\n",
            "Processing file number:73\n",
            "Processing file number:74\n",
            "Processing file number:75\n",
            "Processing file number:76\n",
            "Processing file number:77\n",
            "Processing file number:78\n",
            "Processing file number:79\n",
            "Processing file number:80\n",
            "Processing file number:81\n",
            "Processing file number:82\n",
            "Processing file number:83\n",
            "Processing file number:84\n",
            "Processing file number:85\n",
            "Processing file number:86\n",
            "Processing file number:87\n",
            "Processing file number:88\n",
            "Processing file number:89\n",
            "Processing file number:90\n",
            "Processing file number:91\n",
            "Processing file number:92\n",
            "Processing file number:93\n",
            "Processing file number:94\n",
            "Processing file number:95\n",
            "Processing file number:0\n",
            "Processing file number:1\n",
            "Processing file number:2\n",
            "Processing file number:3\n",
            "Processing file number:4\n",
            "Processing file number:5\n",
            "Processing file number:6\n",
            "Processing file number:7\n",
            "Processing file number:8\n",
            "Processing file number:9\n",
            "Processing file number:10\n",
            "Processing file number:11\n",
            "Processing file number:12\n",
            "Processing file number:13\n",
            "Processing file number:14\n",
            "Processing file number:15\n",
            "Processing file number:16\n",
            "Processing file number:17\n",
            "Processing file number:18\n",
            "Processing file number:19\n",
            "Processing file number:20\n",
            "Processing file number:21\n",
            "Processing file number:22\n",
            "Processing file number:23\n",
            "Processing file number:24\n",
            "Processing file number:25\n",
            "Processing file number:26\n",
            "Processing file number:27\n",
            "Processing file number:28\n",
            "Processing file number:29\n",
            "Processing file number:30\n",
            "Processing file number:31\n",
            "Processing file number:32\n",
            "Processing file number:33\n",
            "Processing file number:34\n",
            "Processing file number:35\n",
            "Processing file number:36\n",
            "Processing file number:37\n",
            "Processing file number:38\n",
            "Processing file number:39\n",
            "Processing file number:40\n",
            "Processing file number:41\n",
            "Processing file number:42\n",
            "Processing file number:43\n",
            "Processing file number:44\n",
            "Processing file number:45\n",
            "Processing file number:46\n",
            "Processing file number:47\n",
            "Processing file number:48\n",
            "Processing file number:49\n",
            "Processing file number:50\n",
            "Processing file number:51\n",
            "Processing file number:52\n",
            "Processing file number:53\n",
            "Processing file number:54\n",
            "Processing file number:55\n",
            "Processing file number:56\n",
            "Processing file number:57\n",
            "Processing file number:58\n",
            "Processing file number:59\n",
            "Processing file number:60\n",
            "Processing file number:61\n",
            "Processing file number:62\n",
            "Processing file number:63\n",
            "Processing file number:64\n",
            "Processing file number:65\n",
            "Processing file number:66\n",
            "Processing file number:67\n",
            "Processing file number:68\n",
            "Processing file number:69\n",
            "Processing file number:70\n",
            "Processing file number:71\n",
            "Processing file number:72\n",
            "Processing file number:73\n",
            "Processing file number:74\n",
            "Processing file number:75\n",
            "Processing file number:76\n",
            "Processing file number:77\n",
            "Processing file number:78\n",
            "Processing file number:79\n",
            "Processing file number:80\n",
            "Processing file number:81\n",
            "Processing file number:82\n",
            "Processing file number:83\n",
            "Processing file number:84\n",
            "Processing file number:85\n",
            "Processing file number:86\n",
            "Processing file number:87\n",
            "Processing file number:88\n",
            "Processing file number:89\n",
            "Processing file number:90\n",
            "Processing file number:91\n",
            "Processing file number:92\n",
            "Processing file number:93\n",
            "Processing file number:94\n",
            "Processing file number:95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "weight_decay=0.0001\n",
        "epochs = 20\n",
        "lr = 0.001\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                            batch_size=batch_size,\n",
        "                                            shuffle=True,\n",
        "                                            pin_memory=True,\n",
        "                                            num_workers=0)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset)\n",
        "valnum = val_dataset.row_count\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset)\n",
        "testnum = test_dataset.row_count\n",
        "\n",
        "\n",
        "model = NSSADNN().to(device)\n",
        "criterion = nn.L1Loss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay, momentum=0.9)\n",
        "torch.optim.lr_scheduler.StepLR(optimizer, 750, gamma=0.1, last_epoch=-1)\n",
        "best_SROCC = -1\n",
        "\n",
        "# training \n",
        "for epoch in range(epochs):\n",
        "      # train\n",
        "      model.train()\n",
        "      LOSS_all = 0\n",
        "      LOSS_NSS = 0\n",
        "      LOSS_q = 0\n",
        "      for i, (patches, (label, features)) in enumerate(train_loader):\n",
        "          patches = patches.to(device)\n",
        "          label = label.to(device)\n",
        "          features = features.to(device).float()\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          outputs_q = model(patches)[0]\n",
        "          outputs_NSS = model(patches)[1]\n",
        "\n",
        "          loss_NSS = criterion(outputs_NSS, features)\n",
        "          loss_q = criterion(outputs_q, label)\n",
        "          loss = loss_NSS + loss_q\n",
        "\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          LOSS_all += float(loss.item())\n",
        "          LOSS_NSS += float(loss_NSS.item())\n",
        "          LOSS_q += float(loss_q.item())\n",
        "      train_loss_all = LOSS_all / (i + 1)\n",
        "      train_loss_NSS = LOSS_NSS / (i + 1)\n",
        "      train_loss_q = LOSS_q / (i + 1)\n",
        "\n",
        "      # val\n",
        "      y_pred = np.zeros(valnum)\n",
        "      y_val = np.zeros(valnum)\n",
        "      model.eval()\n",
        "      L = 0\n",
        "      with torch.no_grad():\n",
        "          for i, (patches, (label, features)) in enumerate(val_loader):\n",
        "              y_val[i] = label.item()\n",
        "              patches = patches.to(device)\n",
        "              label = label.to(device)\n",
        "              outputs_q = model(patches)[0]\n",
        "              score = outputs_q.mean()\n",
        "              y_pred[i] = score\n",
        "              loss = criterion(score, label[0])\n",
        "              L = L + loss.item()\n",
        "      val_loss = L / (i + 1)\n",
        "\n",
        "      val_SROCC = stats.spearmanr(y_pred, y_val)[0]\n",
        "      val_PLCC = stats.pearsonr(y_pred, y_val)[0]\n",
        "      val_KROCC = stats.stats.kendalltau(y_pred, y_val)[0]\n",
        "      val_RMSE = np.sqrt(((y_pred - y_val) ** 2).mean())\n",
        "\n",
        "\n",
        "      print(\"Epoch {} Valid Results: loss={:.3f} SROCC={:.3f} PLCC={:.3f} KROCC={:.3f} RMSE={:.3f}\".format(epoch,\n",
        "                                                                                                            val_loss,\n",
        "                                                                                                            val_SROCC,\n",
        "                                                                                                            val_PLCC,\n",
        "                                                                                                            val_KROCC,\n",
        "                                                                                                            val_RMSE))\n",
        "\n",
        "      if val_SROCC > best_SROCC and epoch > 100:\n",
        "          print(\"Update Epoch {} best valid SROCC\".format(epoch))\n",
        "          print(\"Valid Results: loss={:.3f} SROCC={:.3f} PLCC={:.3f} KROCC={:.3f} RMSE={:.3f}\".format(val_loss,\n",
        "                                                                                                      val_SROCC,\n",
        "                                                                                                      val_PLCC,\n",
        "                                                                                                      val_KROCC,\n",
        "                                                                                                      val_RMSE))\n",
        "\n",
        "          torch.save(model.state_dict(), save_model)\n",
        "          best_SROCC = val_SROCC\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KIYpeyyc5T6",
        "outputId": "0d062b78-b665-4a1f-e403-b2902b1b38ec"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 Valid Results: loss=1.100 SROCC=0.051 PLCC=-0.011 KROCC=0.036 RMSE=1.326\n",
            "Epoch 1 Valid Results: loss=0.941 SROCC=0.011 PLCC=0.054 KROCC=0.005 RMSE=1.204\n",
            "Epoch 2 Valid Results: loss=0.953 SROCC=-0.191 PLCC=-0.052 KROCC=-0.143 RMSE=1.173\n",
            "Epoch 3 Valid Results: loss=0.936 SROCC=-0.007 PLCC=0.108 KROCC=-0.009 RMSE=1.181\n",
            "Epoch 4 Valid Results: loss=0.928 SROCC=-0.005 PLCC=0.126 KROCC=-0.004 RMSE=1.199\n",
            "Epoch 5 Valid Results: loss=0.931 SROCC=0.094 PLCC=0.238 KROCC=0.064 RMSE=1.191\n",
            "Epoch 6 Valid Results: loss=0.934 SROCC=0.114 PLCC=0.158 KROCC=0.088 RMSE=1.188\n",
            "Epoch 7 Valid Results: loss=0.930 SROCC=0.184 PLCC=0.256 KROCC=0.133 RMSE=1.193\n",
            "Epoch 8 Valid Results: loss=0.930 SROCC=0.087 PLCC=0.164 KROCC=0.066 RMSE=1.196\n",
            "Epoch 9 Valid Results: loss=0.926 SROCC=0.283 PLCC=0.361 KROCC=0.211 RMSE=1.197\n",
            "Epoch 10 Valid Results: loss=0.928 SROCC=0.027 PLCC=0.118 KROCC=0.016 RMSE=1.201\n",
            "Epoch 11 Valid Results: loss=0.927 SROCC=0.271 PLCC=0.332 KROCC=0.203 RMSE=1.196\n",
            "Epoch 12 Valid Results: loss=0.928 SROCC=0.273 PLCC=0.294 KROCC=0.203 RMSE=1.199\n",
            "Epoch 13 Valid Results: loss=0.968 SROCC=0.245 PLCC=0.257 KROCC=0.181 RMSE=1.217\n",
            "Epoch 14 Valid Results: loss=0.930 SROCC=0.156 PLCC=0.244 KROCC=0.110 RMSE=1.186\n",
            "Epoch 15 Valid Results: loss=0.925 SROCC=0.289 PLCC=0.284 KROCC=0.210 RMSE=1.164\n",
            "Epoch 16 Valid Results: loss=0.923 SROCC=0.356 PLCC=0.353 KROCC=0.265 RMSE=1.180\n",
            "Epoch 17 Valid Results: loss=0.926 SROCC=0.278 PLCC=0.278 KROCC=0.206 RMSE=1.185\n",
            "Epoch 18 Valid Results: loss=0.936 SROCC=0.256 PLCC=0.236 KROCC=0.189 RMSE=1.162\n",
            "Epoch 19 Valid Results: loss=0.902 SROCC=0.347 PLCC=0.378 KROCC=0.257 RMSE=1.102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# final test\n",
        "torch.save(model.state_dict(), save_model)\n",
        "\n",
        "model.load_state_dict(torch.load(save_model))\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred = np.zeros(testnum)\n",
        "    y_test = np.zeros(testnum)\n",
        "    L = 0\n",
        "    for i, (patches, (label, features)) in enumerate(test_loader):\n",
        "        y_test[i] = label.item()\n",
        "        patches = patches.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        outputs = model(patches)[0]\n",
        "        score = outputs.mean()\n",
        "\n",
        "        y_pred[i] = score\n",
        "        loss = criterion(score, label[0])\n",
        "        L = L + loss.item()\n",
        "test_loss = L / (i + 1)\n",
        "SROCC = stats.spearmanr(y_pred, y_test)[0]\n",
        "PLCC = stats.pearsonr(y_pred, y_test)[0]\n",
        "KROCC = stats.stats.kendalltau(y_pred, y_test)[0]\n",
        "RMSE = np.sqrt(((y_pred - y_test) ** 2).mean())\n",
        "\n",
        "print(\"Final test Results: loss={:.3f} SROCC={:.3f} PLCC={:.3f} KROCC={:.3f} RMSE={:.3f}\".format(test_loss,\n",
        "                                                                                                  SROCC,\n",
        "                                                                                                  PLCC,\n",
        "                                                                                                  KROCC,\n",
        "                                                                                                  RMSE))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrLTQyEodQF9",
        "outputId": "bcb82491-039e-45ed-a303-f856d1a8aca9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final test Results: loss=0.902 SROCC=0.347 PLCC=0.378 KROCC=0.257 RMSE=1.102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzdXFKfdFUxO",
        "outputId": "4da72df7-b933-4d52-aa7a-db390c5ffd5b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3., 4., 3., 3., 2., 5., 5., 3., 4., 5., 5., 5., 4., 4., 5., 1., 4.,\n",
              "       4., 5., 3., 4., 2., 5., 3., 4., 5., 3., 3., 5., 4., 2., 3., 5., 3.,\n",
              "       1., 5., 3., 4., 3., 3., 4., 5., 3., 5., 4., 5., 5., 3., 2., 4., 3.,\n",
              "       5., 2., 5., 4., 4., 4., 4., 1., 5., 2., 5., 3., 4., 5., 4., 5., 3.,\n",
              "       5., 4., 4., 5., 4., 5., 5., 2., 3., 4., 3., 3., 4., 5., 1., 2., 5.,\n",
              "       2., 4., 1., 3., 3., 5., 4., 3., 4., 3., 2.])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b90lIdsqFWrD",
        "outputId": "c854b435-d7ee-4116-8f2e-fc7facc255c5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3.49649525, 3.8488152 , 3.82291579, 3.40156889, 3.73796296,\n",
              "       3.86409712, 3.97929382, 3.43160295, 3.77204633, 3.79290915,\n",
              "       3.8627069 , 3.7951293 , 3.90003753, 3.81461215, 3.77649808,\n",
              "       3.29390693, 3.85351086, 3.76837111, 3.71456218, 3.73433423,\n",
              "       3.78590393, 3.73904967, 3.81949449, 3.67965508, 4.13626575,\n",
              "       3.77891397, 3.45730448, 3.84554648, 3.9262991 , 3.9518013 ,\n",
              "       3.48791361, 3.58318114, 3.8865788 , 3.7758925 , 3.73253369,\n",
              "       3.87430072, 3.62002397, 3.73118401, 3.97094512, 3.73111939,\n",
              "       3.79931974, 3.83701134, 3.55569458, 3.99449873, 3.27101469,\n",
              "       3.93501806, 3.91533494, 4.08376551, 3.72365689, 3.97489405,\n",
              "       3.74845576, 3.32286954, 3.27333713, 3.65396762, 3.70929146,\n",
              "       3.80980587, 3.72893977, 3.68569899, 3.41213322, 3.72953343,\n",
              "       3.83491611, 3.73140526, 3.66633034, 3.38981581, 3.67772722,\n",
              "       4.00991774, 3.59634256, 3.83149457, 3.53208137, 3.92337894,\n",
              "       3.75965118, 3.75458407, 3.76925159, 3.6636138 , 3.52949166,\n",
              "       3.59121656, 3.32384372, 3.95391631, 3.53781819, 3.9281261 ,\n",
              "       3.71640134, 3.82039523, 3.46975684, 3.34185934, 3.65191698,\n",
              "       3.38961244, 3.78500223, 3.7877152 , 3.73460293, 3.52978778,\n",
              "       3.77895713, 3.93861127, 3.66522527, 3.97715259, 3.47686958,\n",
              "       3.76998496])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oUuSx1WgFYj_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}