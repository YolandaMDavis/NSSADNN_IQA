{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wildtrack_multitask_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "145BSapb-tD6YRaQ-kkbOu1ho99LkXdD9",
      "authorship_tag": "ABX9TyND0N85pep3/IZRASIGSsIU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YolandaMDavis/NSSADNN_IQA/blob/wildtrack-iqa/wildtrack_multitask_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "86zTQbaATADZ",
        "outputId": "4cd7da0f-46a3-4d94-a6dd-e68c9f0ce83d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'WildTrack_Raw.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "#Only needed to copy data to local drive can be skipped if zip file is already available in working folder\n",
        "import shutil\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive') # for google colab. adjust accordingly\n",
        "PARENT_DIR = '/content/drive/MyDrive/Wildtrack Group/IQA' \n",
        "\n",
        "# copy and extract tar file\n",
        "shutil.copy(PARENT_DIR + '/data/WildTrack_Raw.zip', 'WildTrack_Raw.zip')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone repo and copy in images. change working directory to repo's wildtrack branch\n",
        "\n",
        "!git clone https://github.com/YolandaMDavis/NSSADNN_IQA.git\n",
        "!mv WildTrack_Raw.zip NSSADNN_IQA/.\n",
        "%cd \"NSSADNN_IQA\"\n",
        "!git checkout wildtrack-iqa\n",
        "\n",
        "with ZipFile('WildTrack_Raw.zip', 'r') as zipObj:\n",
        "   # Extract all the contents of zip file in current directory\n",
        "   zipObj.extractall()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdsaQ5gLscbH",
        "outputId": "a828ac7a-c24b-40bc-a580-eebb0f2bf030"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NSSADNN_IQA'...\n",
            "remote: Enumerating objects: 61, done.\u001b[K\n",
            "remote: Counting objects: 100% (61/61), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 61 (delta 29), reused 28 (delta 8), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (61/61), done.\n",
            "/content/NSSADNN_IQA\n",
            "Branch 'wildtrack-iqa' set up to track remote branch 'wildtrack-iqa' from 'origin'.\n",
            "Switched to a new branch 'wildtrack-iqa'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# director variables\n",
        "root_dir = '/content/NSSADNN_IQA'\n",
        "data_dir = root_dir + '/RAW'\n",
        "image_reference_file_suffix = '_image_references.csv'\n",
        "%cd \"NSSADNN_IQA\""
      ],
      "metadata": {
        "id": "ekH386NcXSpL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41320a8e-1499-45df-f0b1-98a8d492a573"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/NSSADNN_IQA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import yaml\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "def generate_data_files(sample_percentage=1):\n",
        "\n",
        "    image_reference_list = []\n",
        "\n",
        "    subdirectories = list(os.walk(data_dir, topdown=False))[:-1]\n",
        "    for subdir in subdirectories:\n",
        "        image_location = subdir[0]\n",
        "        images = subdir[2]\n",
        "        species_rating = image_location.rsplit('/', 1)[-1].replace('_', ' ')\n",
        "        score = int(species_rating.rsplit(' ', 1)[-1])\n",
        "        species_class = species_rating.rsplit(' ', 1)[:-1][0]\n",
        "        if len(species_class.rsplit(' ', 1)) > 1:\n",
        "            species = species_class.rsplit(' ')[0]\n",
        "            animal_class = ' '.join(species_class.rsplit(' ')[1:])\n",
        "        else:\n",
        "            animal_class = 'Unknown'\n",
        "            species = species_class\n",
        "\n",
        "        for image in images:\n",
        "            image_reference = (image_location, species, animal_class, image, score)\n",
        "            image_reference_list.append(image_reference)\n",
        "\n",
        "    # shuffle then split\n",
        "    seed = 1234\n",
        "    random.Random(seed).shuffle(image_reference_list)\n",
        "    training = image_reference_list[:int(len(image_reference_list) * 0.6 * sample_percentage)]\n",
        "    validation = image_reference_list[-int(len(image_reference_list) * 0.2 * sample_percentage):]\n",
        "    testing = image_reference_list[-int(len(image_reference_list) * 0.2 * sample_percentage):]\n",
        "\n",
        "    # generated reference splits\n",
        "    for dataset in [('training', training), ('validation', validation), ('testing', testing)]:\n",
        "        ref_file_name = root_dir + '/' + dataset[0] + image_reference_file_suffix\n",
        "        with open(ref_file_name, 'w', newline='') as csvfile:\n",
        "            image_ref_writer = csv.writer(csvfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_NONNUMERIC)\n",
        "            image_ref_writer.writerows(dataset[1])\n"
      ],
      "metadata": {
        "id": "WTrUK_gJY7Ze"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# take a percentage of the full data set as a training/test/validation sample\n",
        "sample_size=.05\n",
        "generate_data_files(sample_size)"
      ],
      "metadata": {
        "id": "kBYqLFkEeXJ5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "import torch.nn as nn\n",
        "import random\n",
        "from network import NSSADNN\n",
        "from WildTrackDataset import WildTrackDataset"
      ],
      "metadata": {
        "id": "xs7-7IR8dYVZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_model = root_dir + \"/model.pth\"\n",
        "\n",
        "seed = random.randint(10000000, 99999999)\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "print(\"seed:\", seed)\n",
        "\n",
        "config = {}\n",
        "config[\"patch_size\"] = 32\n",
        "config[\"stride\"] = 16\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "train_dataset = WildTrackDataset(root_dir + '/' + 'training' + image_reference_file_suffix, config, \"train\")\n",
        "val_dataset = WildTrackDataset(root_dir + '/' + 'validation' + image_reference_file_suffix, config, \"validation\")\n",
        "test_dataset = WildTrackDataset(root_dir + '/' + 'testing' + image_reference_file_suffix, config, \"testing\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vt81g7b6ZYlN",
        "outputId": "fc1561d6-e85b-41d6-977a-1ca3ec2a7fea"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "seed: 90076636\n",
            "Processing file number:0\n",
            "Processing file number:1\n",
            "Processing file number:2\n",
            "Processing file number:3\n",
            "Processing file number:4\n",
            "Processing file number:5\n",
            "Processing file number:6\n",
            "Processing file number:7\n",
            "Processing file number:8\n",
            "Processing file number:9\n",
            "Processing file number:10\n",
            "Processing file number:11\n",
            "Processing file number:12\n",
            "Processing file number:13\n",
            "Processing file number:14\n",
            "Processing file number:15\n",
            "Processing file number:16\n",
            "Processing file number:17\n",
            "Processing file number:18\n",
            "Processing file number:19\n",
            "Processing file number:20\n",
            "Processing file number:21\n",
            "Processing file number:22\n",
            "Processing file number:23\n",
            "Processing file number:24\n",
            "Processing file number:25\n",
            "Processing file number:26\n",
            "Processing file number:27\n",
            "Processing file number:28\n",
            "Processing file number:29\n",
            "Processing file number:30\n",
            "Processing file number:31\n",
            "Processing file number:32\n",
            "Processing file number:33\n",
            "Processing file number:34\n",
            "Processing file number:35\n",
            "Processing file number:36\n",
            "Processing file number:37\n",
            "Processing file number:38\n",
            "Processing file number:39\n",
            "Processing file number:40\n",
            "Processing file number:41\n",
            "Processing file number:42\n",
            "Processing file number:43\n",
            "Processing file number:44\n",
            "Processing file number:45\n",
            "Processing file number:46\n",
            "Processing file number:47\n",
            "Processing file number:48\n",
            "Processing file number:49\n",
            "Processing file number:50\n",
            "Processing file number:51\n",
            "Processing file number:52\n",
            "Processing file number:53\n",
            "Processing file number:54\n",
            "Processing file number:55\n",
            "Processing file number:56\n",
            "Processing file number:57\n",
            "Processing file number:58\n",
            "Processing file number:59\n",
            "Processing file number:60\n",
            "Processing file number:61\n",
            "Processing file number:62\n",
            "Processing file number:63\n",
            "Processing file number:64\n",
            "Processing file number:65\n",
            "Processing file number:66\n",
            "Processing file number:67\n",
            "Processing file number:68\n",
            "Processing file number:69\n",
            "Processing file number:70\n",
            "Processing file number:71\n",
            "Processing file number:72\n",
            "Processing file number:73\n",
            "Processing file number:74\n",
            "Processing file number:75\n",
            "Processing file number:76\n",
            "Processing file number:77\n",
            "Processing file number:78\n",
            "Processing file number:79\n",
            "Processing file number:80\n",
            "Processing file number:81\n",
            "Processing file number:82\n",
            "Processing file number:83\n",
            "Processing file number:84\n",
            "Processing file number:85\n",
            "Processing file number:86\n",
            "Processing file number:87\n",
            "Processing file number:88\n",
            "Processing file number:89\n",
            "Processing file number:90\n",
            "Processing file number:91\n",
            "Processing file number:92\n",
            "Processing file number:93\n",
            "Processing file number:94\n",
            "Processing file number:95\n",
            "Processing file number:96\n",
            "Processing file number:97\n",
            "Processing file number:98\n",
            "Processing file number:99\n",
            "Processing file number:100\n",
            "Processing file number:101\n",
            "Processing file number:102\n",
            "Processing file number:103\n",
            "Processing file number:104\n",
            "Processing file number:105\n",
            "Processing file number:106\n",
            "Processing file number:107\n",
            "Processing file number:108\n",
            "Processing file number:109\n",
            "Processing file number:110\n",
            "Processing file number:111\n",
            "Processing file number:112\n",
            "Processing file number:113\n",
            "Processing file number:114\n",
            "Processing file number:115\n",
            "Processing file number:116\n",
            "Processing file number:117\n",
            "Processing file number:118\n",
            "Processing file number:119\n",
            "Processing file number:120\n",
            "Processing file number:121\n",
            "Processing file number:122\n",
            "Processing file number:123\n",
            "Processing file number:124\n",
            "Processing file number:125\n",
            "Processing file number:126\n",
            "Processing file number:127\n",
            "Processing file number:128\n",
            "Processing file number:129\n",
            "Processing file number:130\n",
            "Processing file number:131\n",
            "Processing file number:132\n",
            "Processing file number:133\n",
            "Processing file number:134\n",
            "Processing file number:135\n",
            "Processing file number:136\n",
            "Processing file number:137\n",
            "Processing file number:138\n",
            "Processing file number:139\n",
            "Processing file number:140\n",
            "Processing file number:141\n",
            "Processing file number:142\n",
            "Processing file number:143\n",
            "Processing file number:0\n",
            "Processing file number:1\n",
            "Processing file number:2\n",
            "Processing file number:3\n",
            "Processing file number:4\n",
            "Processing file number:5\n",
            "Processing file number:6\n",
            "Processing file number:7\n",
            "Processing file number:8\n",
            "Processing file number:9\n",
            "Processing file number:10\n",
            "Processing file number:11\n",
            "Processing file number:12\n",
            "Processing file number:13\n",
            "Processing file number:14\n",
            "Processing file number:15\n",
            "Processing file number:16\n",
            "Processing file number:17\n",
            "Processing file number:18\n",
            "Processing file number:19\n",
            "Processing file number:20\n",
            "Processing file number:21\n",
            "Processing file number:22\n",
            "Processing file number:23\n",
            "Processing file number:24\n",
            "Processing file number:25\n",
            "Processing file number:26\n",
            "Processing file number:27\n",
            "Processing file number:28\n",
            "Processing file number:29\n",
            "Processing file number:30\n",
            "Processing file number:31\n",
            "Processing file number:32\n",
            "Processing file number:33\n",
            "Processing file number:34\n",
            "Processing file number:35\n",
            "Processing file number:36\n",
            "Processing file number:37\n",
            "Processing file number:38\n",
            "Processing file number:39\n",
            "Processing file number:40\n",
            "Processing file number:41\n",
            "Processing file number:42\n",
            "Processing file number:43\n",
            "Processing file number:44\n",
            "Processing file number:45\n",
            "Processing file number:46\n",
            "Processing file number:47\n",
            "Processing file number:0\n",
            "Processing file number:1\n",
            "Processing file number:2\n",
            "Processing file number:3\n",
            "Processing file number:4\n",
            "Processing file number:5\n",
            "Processing file number:6\n",
            "Processing file number:7\n",
            "Processing file number:8\n",
            "Processing file number:9\n",
            "Processing file number:10\n",
            "Processing file number:11\n",
            "Processing file number:12\n",
            "Processing file number:13\n",
            "Processing file number:14\n",
            "Processing file number:15\n",
            "Processing file number:16\n",
            "Processing file number:17\n",
            "Processing file number:18\n",
            "Processing file number:19\n",
            "Processing file number:20\n",
            "Processing file number:21\n",
            "Processing file number:22\n",
            "Processing file number:23\n",
            "Processing file number:24\n",
            "Processing file number:25\n",
            "Processing file number:26\n",
            "Processing file number:27\n",
            "Processing file number:28\n",
            "Processing file number:29\n",
            "Processing file number:30\n",
            "Processing file number:31\n",
            "Processing file number:32\n",
            "Processing file number:33\n",
            "Processing file number:34\n",
            "Processing file number:35\n",
            "Processing file number:36\n",
            "Processing file number:37\n",
            "Processing file number:38\n",
            "Processing file number:39\n",
            "Processing file number:40\n",
            "Processing file number:41\n",
            "Processing file number:42\n",
            "Processing file number:43\n",
            "Processing file number:44\n",
            "Processing file number:45\n",
            "Processing file number:46\n",
            "Processing file number:47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "weight_decay=0.0001\n",
        "epochs = 10\n",
        "lr = 0.001\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                            batch_size=batch_size,\n",
        "                                            shuffle=True,\n",
        "                                            pin_memory=True,\n",
        "                                            num_workers=0)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset)\n",
        "valnum = val_dataset.row_count\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset)\n",
        "testnum = test_dataset.row_count\n",
        "\n",
        "model = NSSADNN().to(device)\n",
        "criterion = nn.L1Loss()\n",
        "classify_criterion = nn.NLLLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay, momentum=0.9)\n",
        "torch.optim.lr_scheduler.StepLR(optimizer, 750, gamma=0.1, last_epoch=-1)\n",
        "best_SROCC = -1\n",
        "\n",
        "# training \n",
        "for epoch in range(epochs):\n",
        "      # train\n",
        "      model.train()\n",
        "      LOSS_all = 0\n",
        "      LOSS_NSS = 0\n",
        "      LOSS_q = 0\n",
        "      for i, (patches, (label, features, species)) in enumerate(train_loader):\n",
        "          patches = patches.to(device)\n",
        "          label = label.to(device)\n",
        "          features = features.to(device).float()\n",
        "          species = species.to(device)\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          results = model(patches)\n",
        "          outputs_q = results[0]\n",
        "          outputs_NSS = results[1]\n",
        "          outputs_species = results[2]\n",
        "\n",
        "          loss_NSS = criterion(outputs_NSS, features)\n",
        "          loss_q = criterion(outputs_q, label)\n",
        "          loss_c = classify_criterion(outputs_species, species)\n",
        "          loss = loss_NSS + loss_q\n",
        "\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          LOSS_all += float(loss.item())\n",
        "          LOSS_NSS += float(loss_NSS.item())\n",
        "          LOSS_q += float(loss_q.item())\n",
        "      train_loss_all = LOSS_all / (i + 1)\n",
        "      train_loss_NSS = LOSS_NSS / (i + 1)\n",
        "      train_loss_q = LOSS_q / (i + 1)\n",
        "\n",
        "      # val\n",
        "      y_pred = np.zeros(valnum)\n",
        "      y_val = np.zeros(valnum)\n",
        "      model.eval()\n",
        "      L = 0\n",
        "      with torch.no_grad():\n",
        "          for i, (patches, (label, features, species)) in enumerate(val_loader):\n",
        "              y_val[i] = label.item()\n",
        "              patches = patches.to(device)\n",
        "              label = label.to(device)\n",
        "              outputs_q = model(patches)[0]\n",
        "              score = outputs_q.mean()\n",
        "              y_pred[i] = score\n",
        "              loss = criterion(score, label[0])\n",
        "              L = L + loss.item()\n",
        "      val_loss = L / (i + 1)\n",
        "\n",
        "      val_SROCC = stats.spearmanr(y_pred, y_val)[0]\n",
        "      val_PLCC = stats.pearsonr(y_pred, y_val)[0]\n",
        "      val_KROCC = stats.stats.kendalltau(y_pred, y_val)[0]\n",
        "      val_RMSE = np.sqrt(((y_pred - y_val) ** 2).mean())\n",
        "\n",
        "\n",
        "      print(\"Epoch {} Valid Results: loss={:.3f} SROCC={:.3f} PLCC={:.3f} KROCC={:.3f} RMSE={:.3f}\".format(epoch,\n",
        "                                                                                                            val_loss,\n",
        "                                                                                                            val_SROCC,\n",
        "                                                                                                            val_PLCC,\n",
        "                                                                                                            val_KROCC,\n",
        "                                                                                                            val_RMSE))\n",
        "\n",
        "      if val_SROCC > best_SROCC and epoch > 100:\n",
        "          print(\"Update Epoch {} best valid SROCC\".format(epoch))\n",
        "          print(\"Valid Results: loss={:.3f} SROCC={:.3f} PLCC={:.3f} KROCC={:.3f} RMSE={:.3f}\".format(val_loss,\n",
        "                                                                                                      val_SROCC,\n",
        "                                                                                                      val_PLCC,\n",
        "                                                                                                      val_KROCC,\n",
        "                                                                                                      val_RMSE))\n",
        "\n",
        "          torch.save(model.state_dict(), save_model)\n",
        "          best_SROCC = val_SROCC\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KIYpeyyc5T6",
        "outputId": "45b9b873-196f-47d8-e5d2-104df92b3f90"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 Valid Results: loss=1.145 SROCC=0.029 PLCC=-0.081 KROCC=0.020 RMSE=1.360\n",
            "Epoch 1 Valid Results: loss=1.328 SROCC=0.027 PLCC=-0.056 KROCC=0.014 RMSE=1.565\n",
            "Epoch 2 Valid Results: loss=1.078 SROCC=0.037 PLCC=-0.028 KROCC=0.024 RMSE=1.286\n",
            "Epoch 3 Valid Results: loss=1.005 SROCC=0.004 PLCC=-0.054 KROCC=-0.012 RMSE=1.229\n",
            "Epoch 4 Valid Results: loss=1.164 SROCC=0.018 PLCC=-0.017 KROCC=-0.002 RMSE=1.389\n",
            "Epoch 5 Valid Results: loss=1.085 SROCC=0.044 PLCC=0.106 KROCC=0.020 RMSE=1.266\n",
            "Epoch 6 Valid Results: loss=1.027 SROCC=-0.009 PLCC=0.086 KROCC=-0.018 RMSE=1.206\n",
            "Epoch 7 Valid Results: loss=1.109 SROCC=0.035 PLCC=0.101 KROCC=0.020 RMSE=1.313\n",
            "Epoch 8 Valid Results: loss=1.008 SROCC=0.037 PLCC=0.163 KROCC=0.028 RMSE=1.192\n",
            "Epoch 9 Valid Results: loss=1.051 SROCC=0.044 PLCC=0.179 KROCC=0.036 RMSE=1.220\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# final test\n",
        "torch.save(model.state_dict(), save_model)\n",
        "\n",
        "model.load_state_dict(torch.load(save_model))\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred = np.zeros(testnum)\n",
        "    y_test = np.zeros(testnum)\n",
        "    L = 0\n",
        "    for i, (patches, (label, features)) in enumerate(test_loader):\n",
        "        y_test[i] = label.item()\n",
        "        patches = patches.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        outputs = model(patches)[0]\n",
        "        score = outputs.mean()\n",
        "\n",
        "        y_pred[i] = score\n",
        "        loss = criterion(score, label[0])\n",
        "        L = L + loss.item()\n",
        "test_loss = L / (i + 1)\n",
        "SROCC = stats.spearmanr(y_pred, y_test)[0]\n",
        "PLCC = stats.pearsonr(y_pred, y_test)[0]\n",
        "KROCC = stats.stats.kendalltau(y_pred, y_test)[0]\n",
        "RMSE = np.sqrt(((y_pred - y_test) ** 2).mean())\n",
        "\n",
        "print(\"Final test Results: loss={:.3f} SROCC={:.3f} PLCC={:.3f} KROCC={:.3f} RMSE={:.3f}\".format(test_loss,\n",
        "                                                                                                  SROCC,\n",
        "                                                                                                  PLCC,\n",
        "                                                                                                  KROCC,\n",
        "                                                                                                  RMSE))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrLTQyEodQF9",
        "outputId": "9544874e-563a-4548-9c0d-b1da79ef977d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final test Results: loss=0.894 SROCC=0.419 PLCC=0.394 KROCC=0.314 RMSE=1.083\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzdXFKfdFUxO",
        "outputId": "39d3d918-b75f-468f-b6d1-07997e9e2bee"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3., 3., 3., 3., 4., 5., 5., 2., 5., 4., 5., 5., 2., 5., 2., 4., 3.,\n",
              "       5., 4., 4., 4., 5., 3., 3., 4., 5., 3., 4., 4., 4., 5., 5., 3., 4.,\n",
              "       5., 5., 4., 2., 5., 4., 4., 5., 4., 5., 2., 4., 3., 5., 4., 3., 5.,\n",
              "       4., 2., 3., 3., 4., 3., 3., 4., 5., 4., 2., 2., 3., 4., 5., 5., 3.,\n",
              "       2., 5., 5., 4., 4., 3., 5., 4., 2., 4., 4., 3., 3., 4., 4., 3., 5.,\n",
              "       2., 2., 4., 5., 2., 3., 1., 5., 3., 1., 2., 4., 4., 4., 3., 3., 5.,\n",
              "       4., 3., 3., 3., 5., 3., 3., 5., 5., 4., 5., 4., 5., 3., 1., 4., 3.,\n",
              "       5., 3., 4., 3., 4., 4., 4., 4., 4., 3., 2., 3., 2., 4., 4., 2., 3.,\n",
              "       4., 5., 4., 3., 4., 2., 4., 3., 4., 2., 3., 5., 3., 2., 2., 4., 5.,\n",
              "       4., 3., 5., 3., 4., 4., 4., 2., 3., 4., 3., 2., 1., 4., 4., 5., 3.,\n",
              "       2., 3., 3., 3., 5., 5., 5., 5., 3., 5., 5., 4., 4., 2., 3., 5., 3.,\n",
              "       2., 5., 2., 5., 5., 4., 3., 2., 5., 5., 5., 4., 4., 5., 3., 5., 5.,\n",
              "       3., 5., 4., 4., 4., 2., 2., 3., 5., 1., 4., 5., 4., 2., 3., 5., 5.,\n",
              "       1., 5., 2., 5., 4., 5., 5., 5., 5., 3., 2., 4., 4., 3., 4., 5., 3.,\n",
              "       4., 4., 2., 2., 5., 2., 4., 5., 3., 3., 5., 3., 3., 2., 2., 3., 1.,\n",
              "       2., 3., 5., 5., 2., 5., 3., 4., 5., 5., 4., 5., 4., 4., 1., 2., 3.,\n",
              "       5., 5., 5., 4., 5., 3., 2., 5., 5., 3., 1., 2., 3., 4., 5., 4., 2.,\n",
              "       4., 5., 5., 2., 4., 3., 3., 3., 5., 4., 4., 5., 3., 3., 4., 3., 5.,\n",
              "       3., 2., 3., 2., 4., 3., 3., 4., 2., 4., 5., 5., 4., 3., 3., 5., 1.,\n",
              "       4., 2., 3., 4., 3., 4., 5., 3., 3., 2., 5., 4., 5., 5., 5., 1., 5.,\n",
              "       2., 4., 4., 3., 5., 4., 2., 4., 5., 4., 3., 5., 3., 4., 3., 3., 4.,\n",
              "       5., 4., 2., 2., 3., 5., 4., 5., 3., 5., 4., 5., 3., 3., 5., 2., 5.,\n",
              "       4., 5., 3., 1., 3., 4., 3., 5., 3., 5., 3., 5., 3., 4., 3., 3., 2.,\n",
              "       5., 5., 3., 4., 5., 5., 5., 4., 4., 5., 1., 4., 4., 5., 3., 4., 2.,\n",
              "       5., 3., 4., 5., 3., 3., 5., 4., 2., 3., 5., 3., 1., 5., 3., 4., 3.,\n",
              "       3., 4., 5., 3., 5., 4., 5., 5., 3., 2., 4., 3., 5., 2., 5., 4., 4.,\n",
              "       4., 4., 1., 5., 2., 5., 3., 4., 5., 4., 5., 3., 5., 4., 4., 5., 4.,\n",
              "       5., 5., 2., 3., 4., 3., 3., 4., 5., 1., 2., 5., 2., 4., 1., 3., 3.,\n",
              "       5., 4., 3., 4., 3., 2.])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b90lIdsqFWrD",
        "outputId": "4d260535-68a1-476a-ef5f-596c4b120f1a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3.41472077, 3.26770091, 3.72750759, 3.69558382, 3.96568322,\n",
              "       3.7688179 , 3.90765738, 3.58774161, 3.98070312, 3.81571412,\n",
              "       3.87146568, 3.86927581, 3.95050621, 3.79937816, 3.73624849,\n",
              "       3.65594864, 3.69446135, 3.75809216, 3.79607916, 3.81485724,\n",
              "       4.0171175 , 4.06911278, 3.73132324, 3.56478953, 4.36066103,\n",
              "       4.05292845, 3.73699284, 3.69815445, 3.8316505 , 3.52409196,\n",
              "       3.65771174, 3.89356661, 3.52557898, 4.09866047, 4.15722322,\n",
              "       3.75652814, 3.74555779, 3.73519683, 4.15567493, 3.83318019,\n",
              "       3.87520266, 3.86182022, 3.82869911, 3.92059422, 3.18037224,\n",
              "       3.7416358 , 3.61219788, 3.85446739, 3.75874472, 4.0548439 ,\n",
              "       3.94978094, 3.69557452, 3.74291563, 3.85957766, 3.74868298,\n",
              "       3.99885321, 3.73605227, 3.25028276, 4.17590714, 3.93321729,\n",
              "       3.93958354, 3.17193747, 3.61127806, 3.84204268, 3.97924995,\n",
              "       3.81976461, 3.91324043, 3.52556133, 3.92824244, 4.08065939,\n",
              "       3.78168774, 3.64512205, 3.90056062, 3.95519495, 4.06641722,\n",
              "       3.60584164, 3.92833161, 4.06132078, 3.75082159, 3.77145004,\n",
              "       3.61881566, 3.83631134, 3.56862736, 3.79837465, 3.86133862,\n",
              "       3.94910264, 3.81103587, 3.66199231, 3.77048945, 2.42906618,\n",
              "       3.77507329, 3.706599  , 4.27781677, 3.50853252, 3.80933022,\n",
              "       3.7672646 , 3.96431661, 3.72378349, 3.73493171, 3.63755512,\n",
              "       3.56237078, 3.81157994, 3.80799079, 3.59100318, 3.76495719,\n",
              "       3.49109054, 3.7238121 , 3.79863238, 3.85654259, 4.00333929,\n",
              "       3.84050798, 4.0352726 , 3.73698521, 3.6571064 , 3.78414178,\n",
              "       3.41621327, 3.73935151, 4.09569073, 3.59662795, 4.1028347 ,\n",
              "       3.86068034, 3.71200252, 3.56129885, 3.53400326, 3.94822216,\n",
              "       3.76842809, 3.7872088 , 4.01507378, 3.80452061, 3.82979822,\n",
              "       3.58431172, 3.66759753, 3.91505218, 3.83246207, 3.6947794 ,\n",
              "       3.72219014, 3.66538429, 3.76897669, 3.97180033, 3.76457524,\n",
              "       3.6733551 , 3.79462743, 3.73664498, 3.66203332, 3.83636546,\n",
              "       3.48946452, 3.55687571, 3.78514338, 3.46385741, 3.74891257,\n",
              "       3.75288439, 3.67445874, 3.98638368, 3.84243822, 3.68781161,\n",
              "       3.80515409, 3.66956329, 3.59992838, 3.70678926, 3.67376208,\n",
              "       3.38313675, 3.60879111, 3.81450486, 3.50042057, 3.97679591,\n",
              "       3.68992519, 3.73104525, 3.86240888, 3.82857513, 3.20827579,\n",
              "       3.62043357, 3.91129899, 3.80161214, 3.8293457 , 3.74497914,\n",
              "       3.7701304 , 3.91098976, 3.92784476, 3.84920692, 3.82050347,\n",
              "       3.97406363, 3.82850385, 3.89675784, 3.56642103, 3.83212352,\n",
              "       3.68093371, 3.83032894, 3.93765521, 3.98122144, 3.97705579,\n",
              "       3.70541453, 4.10076714, 3.6106317 , 3.68060493, 3.50012898,\n",
              "       3.65284991, 3.79759169, 3.86882043, 3.74233246, 3.65539718,\n",
              "       3.83343816, 3.65060306, 3.98061419, 3.79442263, 4.07952499,\n",
              "       4.34624481, 3.94245481, 3.71242118, 3.73612142, 3.63154268,\n",
              "       3.69832253, 3.72744703, 3.80475831, 3.64354658, 3.90447068,\n",
              "       3.75489211, 3.66308641, 3.75765204, 4.0265913 , 4.14323378,\n",
              "       4.08617067, 3.73040819, 3.78784132, 3.78963161, 3.7484982 ,\n",
              "       3.76703405, 3.77182031, 3.79444695, 4.01587152, 3.90785766,\n",
              "       3.76434994, 3.33984399, 3.76541901, 3.69454455, 3.65088058,\n",
              "       3.82032132, 3.79295087, 3.78030562, 3.74555278, 3.65935206,\n",
              "       3.53005219, 3.61399531, 3.82599545, 3.5692687 , 3.76499319,\n",
              "       3.70098019, 3.76686645, 3.5551281 , 3.8175354 , 3.88364744,\n",
              "       3.6942265 , 3.7694428 , 3.66779709, 3.64423561, 3.73470759,\n",
              "       3.77770257, 3.64356828, 3.94812608, 3.72466707, 3.77205229,\n",
              "       4.01557207, 3.5269978 , 3.91819382, 3.7406857 , 3.85937619,\n",
              "       3.76729751, 3.80944562, 3.81079245, 3.6926055 , 3.61766529,\n",
              "       3.47845125, 3.69789553, 3.81225944, 3.72405267, 3.97875285,\n",
              "       3.826298  , 3.76231408, 3.82264757, 3.59643602, 3.93699932,\n",
              "       4.13933134, 3.62543607, 3.91762924, 3.67703557, 3.93873215,\n",
              "       3.77908802, 3.80127287, 3.75435114, 3.89656782, 3.84490466,\n",
              "       3.875916  , 3.74951959, 3.59177041, 3.8386035 , 3.58921528,\n",
              "       3.81919336, 3.68142605, 3.7595768 , 4.11344671, 3.98129487,\n",
              "       3.61304069, 3.58067441, 3.67167497, 3.86845398, 3.81369758,\n",
              "       3.89032078, 3.83105946, 3.72235966, 3.44306755, 3.80173564,\n",
              "       3.70122814, 3.58527994, 3.95155907, 3.63523984, 3.75796652,\n",
              "       4.15397596, 4.04956532, 3.72403359, 4.02038813, 3.83673286,\n",
              "       3.64019275, 3.88271713, 3.92037916, 3.59283066, 4.04420328,\n",
              "       3.77696681, 3.88230658, 3.69748807, 3.89103913, 3.59355426,\n",
              "       3.67402768, 3.74527597, 3.69677424, 3.73376918, 3.4011302 ,\n",
              "       3.81116557, 4.02346992, 4.00633097, 3.65261889, 3.83169794,\n",
              "       3.71954703, 3.78790164, 4.01057959, 3.8999052 , 3.89344835,\n",
              "       3.64906955, 3.43419743, 3.88732314, 3.91593695, 3.72558498,\n",
              "       3.91427708, 3.70432305, 3.60863853, 3.76860642, 4.02066946,\n",
              "       3.73868108, 3.7504704 , 3.79599977, 3.86763334, 3.70026803,\n",
              "       3.69700241, 3.66841054, 3.65264153, 3.83299708, 3.79372072,\n",
              "       3.43000937, 3.9965868 , 3.58213496, 3.79763842, 3.70603657,\n",
              "       3.80926609, 3.93026376, 3.62845397, 4.18901062, 3.79179215,\n",
              "       4.06798172, 3.76916957, 3.67655396, 3.93640852, 4.10685635,\n",
              "       4.07609272, 3.81742477, 3.66870022, 4.11921597, 3.79718876,\n",
              "       3.95748711, 3.52387214, 3.93989563, 3.75948787, 3.6273725 ,\n",
              "       3.70626545, 3.95961356, 3.87991714, 4.24437284, 3.82963371,\n",
              "       3.93256998, 3.94900513, 3.85513496, 3.99819303, 3.83445215,\n",
              "       3.718328  , 3.44128704, 3.80848145, 3.72146225, 3.67664027,\n",
              "       4.12589979, 3.96754885, 3.69305015, 3.7596519 , 3.75719643,\n",
              "       4.0325985 , 4.15323734, 3.56439066, 3.7954886 , 3.9001472 ,\n",
              "       3.86888266, 3.71520472, 3.54937243, 3.95075917, 3.72643661,\n",
              "       3.50894427, 3.90572929, 3.63544607, 4.05386019, 3.94801927,\n",
              "       3.70032525, 3.76883149, 3.77582145, 3.6332128 , 4.08440542,\n",
              "       3.3516202 , 3.94261575, 3.90366077, 4.07535076, 3.76368284,\n",
              "       3.89928102, 3.75587416, 4.29264164, 3.25832272, 3.91986489,\n",
              "       3.65750003, 3.69925523, 3.63063216, 3.67708778, 3.48870206,\n",
              "       3.78423691, 3.76217175, 3.7965374 , 3.69389701, 3.62873435,\n",
              "       3.6619966 , 3.72129464, 3.7072494 , 3.81337929, 3.9456501 ,\n",
              "       3.94425511, 3.76534128, 3.89277196, 3.71478534, 3.96934199,\n",
              "       3.78409028, 3.90369964, 4.09688234, 4.07805777, 3.73718333,\n",
              "       3.82813978, 3.81319618, 3.77639794, 3.60891032, 3.66060781,\n",
              "       3.647084  , 3.64948893, 3.76696253, 3.75468111, 3.73531413,\n",
              "       3.59969997, 3.77545023, 3.86464691, 3.70493746, 4.02464294,\n",
              "       3.69962096, 3.87489319])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oUuSx1WgFYj_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}